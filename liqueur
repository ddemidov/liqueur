#!/usr/bin/python

import re

#----------------------------------------------------------------------------
# Configuration
#----------------------------------------------------------------------------
# Nodes with load_avg above this will not be shutdown.
load_tol = 0.4

# Broadcast address for sending wake-on-lan packet.
ifaddr   = "192.168.29.255"

# MAC-addresses of computing nodes.
macaddr  = {
    "node1" : "20:cf:30:e4:1c:e3",
    "node2" : "20:cf:30:4c:dc:6d",
    "node3" : "20:cf:30:e4:1e:99",
    "node4" : "20:cf:30:e4:1e:89",
    }

# Interval in seconds between status updates.
sleepfor = 60

# For a node to be shutdown it has to be idle for this number of intervals
# in a row. So if sleepfor == 60 and max_idle == 20, node has to be idle
# for 20 minutes before it goes down.
max_idle = 20

# Liqueur will try to wake up enough nodes to satisfy pending jobs requirements.
# This is the list of resources that should be met. Each resource is the name
# of gridengine complex as in output of `qstat -F -xml`.
managed_resources = ['cores', 'tesla_2070']

# Returns True if node with a given name should be managed by Liqueur.
def managed_node(hostname):
    # Example with exceptions: node01 and node02 should not be managed.
    #   m = re.match('node(?P<num>\d+)', hostname)
    #   return m and m.group('num') not in ['01', '02']

    # Simple matching:
    return re.match('node.*', hostname)

#----------------------------------------------------------------------------
# Code
#----------------------------------------------------------------------------
import subprocess, time
from lxml   import etree
from syslog import syslog

class Host:
    def __init__(self, name):
	self.name = name
	self.jobs = 0
	self.load = 0
	self.idle = 0

	self.resource = {}

    # Tries to wake the node up.
    def wakeup(self):
	if self.load == '-':
	    if self.name in macaddr:
		syslog("Waking %s up" % h)
		subprocess.Popen(['wol', '-i', ifaddr, macaddr[self.name]])
		self.idle = 0
		return True
	    else:
		syslog("%s has no mac-address")
	return False

    # Shuts the node down.
    def shutdown(self):
	if self.load != '-':
	    if int(self.jobs) == 0:
		self.idle += 1
		if self.idle > max_idle and float(self.load) < load_tol:
		    syslog("Shutting %s down" % self.name)
		    subprocess.Popen(['ssh', self.name, 'poweroff'])
	    else:
		self.idle = 0

hosts = {}

while True:
    # Parse output of qstat and qhost
    qhost = etree.fromstring(subprocess.check_output(
	['qhost', '-q', '-F', '-xml']))
    qstat = etree.fromstring(subprocess.check_output(
	['qstat', '-s', 'p', '-r', '-u', '*', '-xml']))

    # Get resource requests for pending jobs
    require = {"slots" : 0}
    for r in managed_resources: require[r] = 0

    for job in qstat.findall('job_info/job_list'):
	slots = int(job.findtext("slots"))
	require["slots"] += slots

	for r in managed_resources:
	    require[r] += slots * float(
		    job.findtext("hard_request[@name='" + r + "']") or 0)

    # Get host list
    for h in qhost.findall('host'):
	name = h.get('name')
	if not managed_node(name): continue

	if name not in hosts: hosts[name] = Host(name)

	hosts[name].load = h.findtext("hostvalue[@name='load_avg']")
	hosts[name].jobs = h.findtext("queue/queuevalue[@name='slots_used']")

	# Get list of host resources
	hosts[name].resource["slots"] = int(
		h.findtext("hostvalue[@name='num_proc']"))
	for r in managed_resources:
	    hosts[name].resource[r] = float(
		    h.findtext("resourcevalue[@name='" + r + "']"))

    # Analyze queue status
    if require["slots"] > 0:
	# Wake up!
	for h in hosts:
	    if hosts[h].wakeup():
		for r in ["slots"] + managed_resources:
		    require[r] -= hosts[h].resource[r]
		if max(require.values()) <= 0: break
    else:
	# Shut someone down?
	for h in hosts: hosts[h].shutdown()

    time.sleep(sleepfor)
